# QML_SYSTEM Comprehensive Architecture Overview

> **Purpose**: Knowledge transfer document for AI systems to fully comprehend, maintain, and extend the QML Trading System.
> **Date**: 2026-01-07
> **Version**: 2.0.0 (VRD 2.0 Compliant)

---

## 1. Executive Summary

The **QML (Quasimodo-Like) Forensic Trading System** is a professional algorithmic trading research platform focused on detecting and validating specific chart patterns on BTC/USDT. The system follows a rigorous **VRD 2.0 (Validate, Reproduce, Deploy)** methodology to ensure edge validity before live deployment.

### Core Philosophy
1. **Validate Reality of Edge** â€” Statistical proof that patterns predict price movement  
2. **Understand Why It Works** â€” Feature analysis of winning vs losing trades  
3. **Assess Durability** â€” Walk-forward and regime analysis  
4. **Identify Failure Modes** â€” Drawdown and stress testing  
5. **Define Deployment Rules** â€” Risk limits and position sizing

---

## 2. File Structure (Exhaustive)

```
QML_SYSTEM/
â”œâ”€â”€ cli/                            # Command-line entry points
â”‚   â”œâ”€â”€ run_backtest.py             # PRIMARY: Backtest execution with detector
â”‚   â”œâ”€â”€ run_grid_search.py          # Parameter optimization loop
â”‚   â””â”€â”€ run_validation.py           # VRD validation suite runner
â”‚
â”œâ”€â”€ src/                            # Core library (importable modules)
â”‚   â”œâ”€â”€ __init__.py                 # Package initialization
â”‚   â”œâ”€â”€ main.py                     # Alternative entry point
â”‚   â”œâ”€â”€ schemas.py                  # Data contracts & validation
â”‚   â”œâ”€â”€ data_engine.py              # Master data fetching/storage
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                       # Fundamental abstractions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ models.py               # Candle, Signal, Trade, SwingPoint dataclasses
â”‚   â”‚
â”‚   â”œâ”€â”€ detection/                  # Pattern detection algorithms
â”‚   â”‚   â”œâ”€â”€ __init__.py             # Factory exports
â”‚   â”‚   â”œâ”€â”€ base.py                 # BaseDetector ABC
â”‚   â”‚   â”œâ”€â”€ factory.py              # get_detector() factory function
â”‚   â”‚   â”œâ”€â”€ v2_atr.py               # PRIMARY: ATRDetector (v2.0.0)
â”‚   â”‚   â”œâ”€â”€ v1_rolling.py           # LEGACY: RollingWindowDetector
â”‚   â”‚   â”œâ”€â”€ swing.py                # Swing point detection
â”‚   â”‚   â”œâ”€â”€ structure.py            # Market structure analysis
â”‚   â”‚   â”œâ”€â”€ choch.py                # Change of Character detection
â”‚   â”‚   â”œâ”€â”€ bos.py                  # Break of Structure detection
â”‚   â”‚   â”œâ”€â”€ detector.py             # Legacy composite detector
â”‚   â”‚   â””â”€â”€ legacy/                 # Archived versions (v1.0.0, v1.1.0)
â”‚   â”‚
â”‚   â”œâ”€â”€ validation/                 # VRD 2.0 statistical validation
â”‚   â”‚   â”œâ”€â”€ __init__.py             # Module exports
â”‚   â”‚   â”œâ”€â”€ base.py                 # Base validation classes
â”‚   â”‚   â”œâ”€â”€ validator.py            # StrategyValidator orchestrator
â”‚   â”‚   â”œâ”€â”€ permutation.py          # Permutation test (edge significance)
â”‚   â”‚   â”œâ”€â”€ monte_carlo.py          # Monte Carlo simulation
â”‚   â”‚   â”œâ”€â”€ bootstrap.py            # Block bootstrap confidence intervals
â”‚   â”‚   â”œâ”€â”€ walk_forward.py         # Purged walk-forward optimization
â”‚   â”‚   â”œâ”€â”€ database.py             # Experiment tracking database
â”‚   â”‚   â””â”€â”€ tracker.py              # Validation state tracking
â”‚   â”‚
â”‚   â”œâ”€â”€ reporting/                  # Output generation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dossier.py              # HTML report generator
â”‚   â”‚   â”œâ”€â”€ storage.py              # ExperimentLogger (SQLite)
â”‚   â”‚   â”œâ”€â”€ visuals.py              # Plotly chart generation
â”‚   â”‚   â””â”€â”€ templates/              # Jinja2 HTML templates
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/                   # Orchestration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ orchestrator.py         # ValidationOrchestrator (full pipeline)
â”‚   â”‚
â”‚   â”œâ”€â”€ features/                   # Feature engineering
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ engineer.py             # FeatureEngineer class
â”‚   â”‚   â”œâ”€â”€ library.py              # Feature calculation library
â”‚   â”‚   â””â”€â”€ regime.py               # Market regime detection
â”‚   â”‚
â”‚   â”œâ”€â”€ ml/                         # Machine learning
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ predictor.py            # XGBoostPredictor
â”‚   â”‚   â”œâ”€â”€ model.py                # Model definitions
â”‚   â”‚   â”œâ”€â”€ trainer.py              # Training pipeline
â”‚   â”‚   â””â”€â”€ labeler.py              # Trade outcome labeling
â”‚   â”‚
â”‚   â”œâ”€â”€ backtest/                   # Backtesting engine
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ engine.py               # BacktestEngine implementation
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                       # Data handling
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ fetcher.py              # Exchange data fetcher
â”‚   â”‚   â”œâ”€â”€ enhanced_fetcher.py     # Multi-source fetcher
â”‚   â”‚   â”œâ”€â”€ database.py             # Data persistence
â”‚   â”‚   â”œâ”€â”€ integrity.py            # DataValidator
â”‚   â”‚   â””â”€â”€ models.py               # Data-specific models
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/                   # Post-trade analysis
â”‚   â”‚   â””â”€â”€ sensitivity.py          # Parameter sensitivity visualization
â”‚   â”‚
â”‚   â”œâ”€â”€ deployment/                 # Production utilities
â”‚   â”‚   â”œâ”€â”€ gatekeeper.py           # Deployment checks
â”‚   â”‚   â””â”€â”€ paper_trader.py         # Paper trading execution
â”‚   â”‚
â”‚   â”œâ”€â”€ strategies/                 # Strategy adapters
â”‚   â”œâ”€â”€ trading/                    # Live trading interface
â”‚   â”œâ”€â”€ alerts/                     # Alert system
â”‚   â”œâ”€â”€ dashboard/                  # Web dashboard
â”‚   â””â”€â”€ utils/                      # Shared utilities
â”‚       â””â”€â”€ indicators.py           # Technical indicator calculations
â”‚
â”œâ”€â”€ config/                         # Configuration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ default.yaml                # Default parameters
â”‚   â”œâ”€â”€ settings.py                 # Settings loader
â”‚   â””â”€â”€ strategies/                 # Strategy-specific configs
â”‚
â”œâ”€â”€ data/                           # Data storage
â”‚   â”œâ”€â”€ processed/                  # Clean parquet files
â”‚   â”‚   â””â”€â”€ BTC/
â”‚   â”‚       â”œâ”€â”€ 1h_master.parquet   # 1-hour OHLCV + ATR
â”‚   â”‚       â””â”€â”€ 4h_master.parquet   # 4-hour OHLCV + ATR (PRIMARY)
â”‚   â”œâ”€â”€ raw/                        # Raw API downloads
â”‚   â””â”€â”€ samples/                    # Sample data for tests
â”‚
â”œâ”€â”€ results/                        # Output artifacts
â”‚   â”œâ”€â”€ experiments.db              # SQLite experiment log
â”‚   â”œâ”€â”€ atr/                        # ATR strategy dossiers
â”‚   â”œâ”€â”€ charts/                     # Generated visualizations
â”‚   â””â”€â”€ reports/                    # HTML dossiers
â”‚
â”œâ”€â”€ tests/                          # Test suite
â”‚   â”œâ”€â”€ test_detection.py           # Detection unit tests
â”‚   â”œâ”€â”€ test_statistics.py          # Statistical validation tests
â”‚   â”œâ”€â”€ test_vrd.py                 # VRD module tests
â”‚   â”œâ”€â”€ test_walk_forward.py        # Walk-forward tests
â”‚   â”œâ”€â”€ unit/                       # Unit tests
â”‚   â””â”€â”€ integration/                # Integration tests
â”‚
â”œâ”€â”€ notebooks/                      # Research notebooks
â”‚   â””â”€â”€ visual_lab.ipynb
â”‚
â”œâ”€â”€ docs/                           # Documentation
â”œâ”€â”€ archive/                        # Legacy code (reference only)
â”œâ”€â”€ models/                         # Trained ML models
â”œâ”€â”€ logs/                           # Runtime logs
â”œâ”€â”€ docker/                         # Docker configs
â”œâ”€â”€ scripts/                        # Utility scripts
â”‚
â”œâ”€â”€ README.md                       # Project overview
â”œâ”€â”€ SYSTEM_CONTEXT.md               # AI agent memory
â”œâ”€â”€ ROAD MAP.md                     # Development roadmap
â”œâ”€â”€ QML PATTERN EXPLAINED.md        # Pattern theory
â”œâ”€â”€ BETA DETECTION LOGIC.md         # Detection algorithm docs
â”œâ”€â”€ pyproject.toml                  # Python project config
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ Dockerfile                      # Container definition
â””â”€â”€ docker-compose.yml              # Orchestration config
```

---

## 3. System Workflow (Brain-Body-Recorder Pattern)

The system follows a **three-layer architecture**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 python -m cli.run_backtest                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ“‚ DATA LOADER                                              â”‚
â”‚  data/processed/BTC/4h_master.parquet â†’ DataFrame           â”‚
â”‚                                                              â”‚
â”‚  Key Function: load_master_data()                            â”‚
â”‚  Location: src/data_engine.py                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ§  BRAIN: Pattern Detection (src/detection/)               â”‚
â”‚                                                              â”‚
â”‚  â”œâ”€â”€ ATRDirectionalChange     Swing point detection         â”‚
â”‚  â”‚   â””â”€â”€ Updates bar-by-bar, confirms extremes via ATR      â”‚
â”‚  â”‚                                                           â”‚
â”‚  â””â”€â”€ ATRDetector              QML pattern assembly          â”‚
â”‚      â””â”€â”€ 3 extremes â†’ Pattern â†’ Signal with SL/TP           â”‚
â”‚                                                              â”‚
â”‚  Output: List[Signal] with:                                  â”‚
â”‚    - entry_price, stop_loss, take_profit                     â”‚
â”‚    - validity_score (0.0-1.0)                                â”‚
â”‚    - pattern geometry (p1-p5 coordinates)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ‹ï¸ BODY: Backtest Engine (cli/run_backtest.py)             â”‚
â”‚                                                              â”‚
â”‚  BacktestEngine class:                                       â”‚
â”‚    - Consumes signals chronologically                        â”‚
â”‚    - Opens trades at signal.entry_price                      â”‚
â”‚    - Tracks SL/TP exit conditions each bar                   â”‚
â”‚    - Records equity curve and drawdowns                      â”‚
â”‚                                                              â”‚
â”‚  Output: Dict with:                                          â”‚
â”‚    - trades: List[Trade]                                     â”‚
â”‚    - metrics: sharpe, win_rate, profit_factor, max_dd        â”‚
â”‚    - equity_curve: List[float]                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ“¼ FLIGHT RECORDER: Reporting (src/reporting/)              â”‚
â”‚                                                              â”‚
â”‚  ExperimentLogger (storage.py):                              â”‚
â”‚    - SQLite database: results/experiments.db                 â”‚
â”‚    - Stores: run_id, config, metrics, timestamp              â”‚
â”‚    - Queryable: get_top_runs(), get_recent_runs()            â”‚
â”‚                                                              â”‚
â”‚  DossierGenerator (dossier.py):                              â”‚
â”‚    - Standalone HTML report                                  â”‚
â”‚    - Embedded Plotly charts (equity, drawdown)               â”‚
â”‚    - Trade log table                                         â”‚
â”‚    - Full config for reproducibility                         â”‚
â”‚                                                              â”‚
â”‚  Output:                                                     â”‚
â”‚    - results/experiments.db                                  â”‚
â”‚    - results/atr/{run_id}_dossier.html                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detailed Flow Sequence

1. **CLI Invocation**: `python -m cli.run_backtest --symbol BTCUSDT --timeframe 4h`

2. **Configuration Loading**:
   - `config/default.yaml` â†’ parsed into `BacktestConfig` dataclass
   - CLI args override YAML defaults

3. **Data Loading** (`load_data()`):
   - Loads parquet from `data/processed/BTC/4h_master.parquet`
   - Validates schema: time, Open, High, Low, Close, Volume, ATR
   - Filters by date range if specified

4. **Detector Initialization** (`get_detector()`):
   - Factory pattern selects detector: `"atr"` â†’ `ATRDetector`
   - Configures: `atr_lookback=14`, `window_size=200`

5. **Pattern Detection** (`detector.detect(df)`):
   - Bar-by-bar iteration with `ATRDirectionalChange`
   - On each new confirmed extreme, check for pattern
   - Pattern validation: geometric ratios, ATR-normalized depth
   - Generate `Signal` with entry, SL, TP, validity score

6. **Trade Simulation** (`engine.run(df, signals)`):
   - Iterate bars chronologically
   - Match pending signals to current bar
   - Open trade if signal time matches
   - Check SL/TP conditions on each bar for open trades
   - Close on hit or at end of data

7. **Metrics Calculation** (`_calculate_metrics()`):
   - Win rate, profit factor, Sharpe ratio
   - Maximum drawdown, recovery factor
   - Average trade duration

8. **Result Persistence**:
   - `ExperimentLogger.log_run()` â†’ SQLite insert
   - `DossierGenerator.generate_html()` â†’ HTML file

---

## 4. Core Component Deep-Dive

### 4.1 Detection Module (`src/detection/`)

#### ATRDirectionalChange Engine
```python
# Location: src/detection/v2_atr.py, lines 80-266

class ATRDirectionalChange:
    """ATR-based swing point detector."""
    
    def __init__(self, atr_lookback: int = 14):
        # State: pending extreme, confirmed extremes list, direction
        
    def update(self, i, time_index, high, low, close):
        """Process bar i, check for extreme confirmation.
        
        Confirmation Rule: Price reverses by 1 ATR from pending extreme.
        """
        
    @property
    def extreme_count(self) -> int:
        """Number of confirmed extremes."""
```

#### ATRDetector Pattern Assembly
```python
# Location: src/detection/v2_atr.py, lines 273-713

class ATRDetector(BaseDetector):
    """QML Pattern Detector using ATR Directional Change."""
    
    def detect(self, candles, symbol, timeframe) -> List[Signal]:
        """Main entry point.
        
        1. Initialize ATRDirectionalChange
        2. Iterate bars, call update()
        3. When new extreme confirmed, check for 3-extreme pattern
        4. Validate pattern geometry
        5. Generate Signal if valid
        """
        
    def _validate_bullish_pattern(self, left, head, right, atr):
        """Pattern validation criteria:
        - head_depth_ratio: 0.5 <= depth/ATR <= 3.0
        - Shoulder symmetry check
        - Neckline angle constraints
        """
```

### 4.2 Core Models (`src/core/models.py`)

| Class | Purpose | Key Fields |
|-------|---------|------------|
| `Candle` | OHLCV unit | timestamp, open, high, low, close, volume |
| `Signal` | Trade opportunity | entry_price, stop_loss, take_profit, validity_score, direction |
| `Trade` | Trade lifecycle | entry_time, exit_time, pnl_pct, result, side |
| `SwingPoint` | Market pivot | timestamp, price, swing_type (HIGH/LOW) |

### 4.3 Validation Module (`src/validation/`)

The validation pipeline implements VRD 2.0:

```python
# Location: src/validation/validator.py

class StrategyValidator:
    """Orchestrates 4 validation methods."""
    
    def run_full_validation(self, strategy_name, df, objective_fn, param_grid):
        """
        1. Purged Walk-Forward (n_folds=10)
           - Train on IS, test on OOS
           - Purge + embargo to prevent leakage
           
        2. Permutation Test (n=10,000)
           - Shuffle returns, recalculate Sharpe
           - P-value for edge significance
           
        3. Monte Carlo (n=50,000)
           - Simulate equity paths
           - 5%/95% confidence cones
           
        4. Bootstrap (n=5,000)
           - Block bootstrap for autocorrelation
           - CI on Sharpe, win rate, max DD
        """
```

### 4.4 Pipeline Orchestrator (`src/pipeline/orchestrator.py`)

```python
class ValidationOrchestrator:
    """7-stage pipeline execution."""
    
    Stages:
    1. DATA_LOADING      â†’ Load & validate OHLCV
    2. FEATURE_ENGINEERING â†’ 200+ features per pattern
    3. REGIME_DETECTION  â†’ K-means market regimes
    4. WALK_FORWARD      â†’ Purged WFO
    5. STATISTICAL_TESTING â†’ Permutation + MC
    6. DIAGNOSTICS       â†’ Feature importance
    7. REPORT_GENERATION â†’ HTML dossier
```

### 4.5 Feature Engineering (`src/features/engineer.py`)

Features are organized into categories:

| Category | Examples |
|----------|----------|
| Geometric | head_depth_ratio, shoulder_symmetry, neckline_slope |
| Temporal | pattern_duration_bars |
| Volume | volume_at_head, obv_divergence |
| Context | atr_percentile, rsi_at_entry, adx_strength |
| Correlation | btc_correlation |

### 4.6 ML Predictor (`src/ml/predictor.py`)

```python
class XGBoostPredictor:
    """Binary classifier for trade outcomes."""
    
    def prepare_data(trades_df, df) -> (X, y):
        """Extract features, label WIN=1, LOSS=0."""
        
    def train(X, y, test_size=0.2):
        """Train XGBoost with early stopping."""
        
    def predict(signal) -> float:
        """Probability of WIN (0.0-1.0)."""
```

---

## 5. Design Rationale

### 5.1 Architectural Decisions

| Decision | Rationale |
|----------|-----------|
| **Brain-Body-Recorder** | Separation of concerns: detection is pure, backtest is stateful, logging is persistent |
| **ATR-based Detection** | Price-action driven replaces naive windowing; pivots confirmed by volatility |
| **Dataclasses everywhere** | Type safety, IDE support, serialization via `asdict()` |
| **YAML configuration** | Human-readable, version-controllable, no code changes for param tuning |
| **SQLite for experiments** | Lightweight, queryable, portable; no external DB required |
| **Plotly for charts** | Interactive, embeddable HTML, professional appearance |

### 5.2 Coding Conventions

- **Docstrings**: NumPy style with Args/Returns sections
- **Type hints**: All function signatures typed
- **Constants**: UPPER_SNAKE_CASE at module top
- **Error handling**: Custom exceptions in `src/core/exceptions.py`
- **Logging**: `logging.getLogger(__name__)` pattern

### 5.3 Performance Considerations

- **NumPy vectorization**: Price arrays processed without Python loops where possible
- **Lazy loading**: Parquet files load only requested columns
- **Caching**: ATR calculated once, stored in master parquet
- **Parallel execution**: `n_jobs` parameter in orchestrator for multi-core

---

## 6. Usage Process

### 6.1 Setup

```bash
# Clone and setup
cd QML_SYSTEM
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# Build master data (fetches 4 years BTC OHLCV)
python -m src.data_engine
```

### 6.2 Running Backtests

```bash
# Default (BTCUSDT 4h, ATR detector)
python -m cli.run_backtest

# Custom parameters
python -m cli.run_backtest \
  --symbol BTCUSDT \
  --timeframe 4h \
  --detector atr \
  --min-validity 0.7 \
  --stop-loss-atr 1.5 \
  --take-profit-atr 3.0

# Grid search
python -m cli.run_grid_search
```

### 6.3 Running Validation

```bash
# Full VRD validation
python -m cli.run_validation --trades results/trades.csv

# Or programmatically:
from src.validation import create_validator

validator = create_validator(
    output_dir="validation_results",
    n_folds=10,
    n_permutations=10000
)
report = validator.run_statistical_validation(trade_returns)
```

### 6.4 Querying Experiments

```python
from src.reporting import ExperimentLogger

logger = ExperimentLogger()

# Best by Sharpe
best = logger.get_top_runs(metric='sharpe_ratio', limit=5)

# Filter by symbol
btc_runs = logger.query_runs(symbol='BTCUSDT', min_trades=30)
```

---

## 7. Integration Points

### 7.1 External Dependencies

| Library | Purpose | Integration |
|---------|---------|-------------|
| `ccxt` | Exchange data fetching | `src/data/fetcher.py` |
| `pandas` | Data manipulation | Throughout |
| `numpy` | Numerical operations | Detection, validation |
| `plotly` | Interactive charts | `src/reporting/visuals.py` |
| `xgboost` | ML classifier | `src/ml/predictor.py` |
| `scipy` | Statistical tests | `src/validation/` |
| `pyarrow` | Parquet I/O | Data engine |
| `pyyaml` | Config parsing | `config/settings.py` |
| `jinja2` | HTML templating | `src/reporting/dossier.py` |

### 7.2 Data Interfaces

**Input Contract (OHLCV)**:
```python
# Required columns
['time', 'Open', 'High', 'Low', 'Close', 'Volume', 'ATR']

# time: datetime64[ns] UTC
# OHLCV: float64
# ATR: float64 (pre-calculated)
```

**Output Contract (Pattern CSV)**:
```python
REQUIRED_PATTERN_COLUMNS = [
    'pattern_id', 'direction', 'validity_score',
    'p1_timestamp', 'p1_price',  # Left shoulder
    'p2_timestamp', 'p2_price',  # First pivot
    'p3_timestamp', 'p3_price',  # Head
    'p4_timestamp', 'p4_price',  # Second pivot
    'p5_timestamp', 'p5_price',  # Entry point
    'entry_price', 'stop_loss', 'take_profit',
    'result', 'pnl_pct'
]
```

### 7.3 CLI Interface

```bash
# Pattern detection workflow
/run-atr-detector  # Defined in .agent/workflows/

# CLI arguments follow argparse conventions
--symbol, --timeframe, --detector, --min-validity
--start-date, --end-date
--output-dir
```

---

## 8. Potential Limitations and Future Considerations

### 8.1 Known Constraints

| Limitation | Impact | Mitigation |
|------------|--------|------------|
| Single-asset focus (BTC) | No cross-asset correlation | Future: Multi-asset support |
| Sequential trade execution | No concurrent positions | Config: `max_concurrent_trades=1` |
| Lookback bias in pattern definition | Feature leakage risk | Purged walk-forward validation |
| Fixed SL/TP ratios | Suboptimal for volatility regimes | Adaptive ATR multipliers |
| XGBoost only | Limited model exploration | Future: Ensemble models |

### 8.2 Enhancement Roadmap

From `ROAD MAP.md`:
1. **Bearish patterns**: Inverse QML detection (planned)
2. **Multi-timeframe analysis**: Confluence detection across 1h/4h/D
3. **Real-time detection**: WebSocket integration for live markets
4. **Portfolio management**: Multi-position risk allocation
5. **Alternative ML**: LightGBM, neural networks for pattern classification

### 8.3 Technical Debt

- `src/detection/detector.py` duplicates logic with `v2_atr.py`
- Some legacy code remains in `archive/` without clear deprecation notes
- Test coverage gaps in `src/ml/` and `src/deployment/`

---

## 9. Quick Reference

### Key File â†’ Purpose Mapping

| When you need to... | Look at... |
|---------------------|------------|
| Run a backtest | `cli/run_backtest.py` |
| Add a new detector | `src/detection/base.py` â†’ implement `BaseDetector` |
| Modify pattern validation | `src/detection/v2_atr.py` â†’ `_validate_bullish_pattern()` |
| Add new features | `src/features/engineer.py` |
| Change validation params | `config/default.yaml` â†’ `validation:` section |
| Query past experiments | `src/reporting/storage.py` â†’ `ExperimentLogger` |
| Customize HTML reports | `src/reporting/dossier.py` |
| Understand data format | `src/schemas.py` |

### Command Cheat Sheet

```bash
# Data
python -m src.data_engine                    # Build master store

# Backtest
python -m cli.run_backtest                   # Default run
python -m cli.run_grid_search                # Param search

# Validation
python -m cli.run_validation                 # Full VRD

# Dashboard
python -m src.dashboard.app                  # Web UI

# Tests
pytest tests/ -v                             # All tests
pytest tests/test_detection.py -v            # Detection only
```

---

## 10. Summary for AI Systems

To maintain and extend this system:

1. **Understand the flow**: Data â†’ Detection â†’ Backtest â†’ Validation â†’ Report
2. **Respect dataclasses**: Always use `Candle`, `Signal`, `Trade` from `src/core/models.py`
3. **Follow factory patterns**: Use `get_detector()` not direct instantiation
4. **Validate statistically**: Never trust backtest results without VRD 2.0 validation
5. **Log everything**: Use `ExperimentLogger` for reproducibility
6. **Configuration over code**: Parameters go in YAML, not hardcoded

The system is designed for **forensic analysis** â€” every decision should be traceable, every result reproducible.
